# -*- coding: utf-8 -*-
"""ProzhePelak V1.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1soIwEKHWnkPo-mODzOhGu6P5U13N1nPK
"""

import os
import zipfile
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from google.colab import drive

drive.mount("/content/drive", force_remount=True)

zip_path = '/content/drive/MyDrive/Car Plate Dataset.zip'
extract_path = '/content/car_dataset'
dataset_path = '/content/car_dataset/Car Plate Dataset'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(os.listdir('/content/car_dataset/Car Plate Dataset'))
print(os.listdir('/content/car_dataset/Car Plate Dataset/images'))

metadata = pd.read_csv(os.path.join(extract_path, 'Car Plate Dataset', 'MetaData.csv'))
metadata['image_path'] = metadata['image_id'].apply(lambda x: os.path.join(extract_path, 'Car Plate Dataset', 'images', f'{x}.jpeg'))

metadata = metadata[metadata['image_id'] != '111']

file_to_remove = os.path.join(extract_path, 'Car Plate Dataset', 'images', '111.jpeg')
if os.path.exists(file_to_remove):
    os.remove(file_to_remove)
    print(f"File {file_to_remove} has been removed.")

print("Contents of extracted folder:")
print(os.listdir(extract_path))
print("\nContents of dataset folder:")
print(os.listdir(dataset_path))
print("\nContents of images folder:")
print(os.listdir(os.path.join(dataset_path, 'images')))

print("\nSample image paths:")
print(metadata['image_path'].head())

def check_image_files(metadata):
    missing_files = []
    for _, row in metadata.iterrows():
        if not os.path.exists(row['image_path']):
            missing_files.append(row['image_path'])

    if missing_files:
        print(f"Warning: {len(missing_files)} image files are missing.")
        print("First few missing files:")
        print(missing_files[:5])
    else:
        print("All image files exist.")

check_image_files(metadata)

print(f"befor filter : {len(metadata)}")
metadata = metadata[metadata['image_path'].apply(os.path.exists)]
print(f"after filter : {len(metadata)}")

label_encoders = {}
categorical_columns = ['name', 'color', 'direction']  # Removed 'type'

for column in categorical_columns:
    le = LabelEncoder()
    metadata[f'{column}_encoded'] = le.fit_transform(metadata[column])
    label_encoders[column] = le

train_data, val_data = train_test_split(metadata, test_size=0.2, random_state=42)

img_size = (224, 224)
batch_size = 16

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=False,
    vertical_flip=False,
    fill_mode='nearest',
    brightness_range=[0.9, 1.1],
    channel_shift_range=20.0,
    preprocessing_function=lambda x: tf.image.random_jpeg_quality(x, 75, 95)
)

val_datagen = ImageDataGenerator(rescale=1./255)

def preprocess_image(image_path, target_size=(224, 224)):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = img_array / 255.0
    return img_array

def data_generator(data, batch_size, is_training=True):
    while True:
        for i in range(0, len(data), batch_size):
            batch_data = data.iloc[i:i+batch_size]
            batch_images = []
            batch_labels = {col: [] for col in categorical_columns}

            for _, row in batch_data.iterrows():
                img = preprocess_image(row['image_path'])
                batch_images.append(img)

                for col in categorical_columns:
                    batch_labels[col].append(label_encoders[col].transform([row[col]])[0])

            batch_images = np.array(batch_images)
            for col in categorical_columns:
                batch_labels[col] = np.array(batch_labels[col])

            yield batch_images, batch_labels

class AttentionLayer(layers.Layer):
    def __init__(self):
        super(AttentionLayer, self).__init__()

    def build(self, input_shape):
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1),
                                 initializer="normal")
        self.b = self.add_weight(name="att_bias", shape=(1,),
                                 initializer="zeros")
        super(AttentionLayer, self).build(input_shape)

    def call(self, x):
        et = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)
        at = tf.keras.backend.softmax(et, axis=1)
        output = x * at
        return output

    def compute_output_shape(self, input_shape):
        return input_shape

base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

inputs = layers.Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.3)(x)
x = AttentionLayer()(x)

outputs = {}
for column in categorical_columns:
    num_classes = len(label_encoders[column].classes_)
    outputs[column] = layers.Dense(num_classes, activation='softmax', name=column)(x)

model = models.Model(inputs=inputs, outputs=outputs)

loss_weights = {
    'name': 1.5,
    'color': 1.0,
    'direction': 1.0
}

initial_learning_rate = 0.001

optimizer = Adam(learning_rate=initial_learning_rate, clipnorm=1.0)

model.compile(optimizer=optimizer,
              loss={col: 'sparse_categorical_crossentropy' for col in categorical_columns},
              loss_weights=loss_weights,
              metrics={col: 'accuracy' for col in categorical_columns})

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)
model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')

history = model.fit(
    data_generator(train_data, batch_size),
    steps_per_epoch=len(train_data) // batch_size,
    epochs=100,
    validation_data=data_generator(val_data, batch_size, is_training=False),
    validation_steps=len(val_data) // batch_size,
    callbacks=[reduce_lr, model_checkpoint]
)

import matplotlib.pyplot as plt

def plot_training_history(history):
    print(history.history.keys())

    plt.figure(figsize=(12, 5))
    plt.subplot(121)
    for key in history.history.keys():
        if 'acc' in key and 'val' not in key:
            plt.plot(history.history[key], label=key)
    for key in history.history.keys():
        if 'acc' in key and 'val' in key:
            plt.plot(history.history[key], label=key)
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(loc='lower right')

    plt.subplot(122)
    for key in history.history.keys():
        if 'loss' in key and 'val' not in key:
            plt.plot(history.history[key], label=key)
    for key in history.history.keys():
        if 'loss' in key and 'val' in key:
            plt.plot(history.history[key], label=key)
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(loc='upper right')

    plt.tight_layout()
    plt.show()

plot_training_history(history)

import os

save_dir = '/content/drive/MyDrive/PlateModel'
os.makedirs(save_dir, exist_ok=True)
model.save(os.path.join(save_dir, 'car_plate_model.keras'))

import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open('/content/drive/MyDrive/PlateModel/car_plate_model.tflite', 'wb') as f:
    f.write(tflite_model)

def predict_car_info(image_path):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    predictions = model.predict(img_array)

    results = {}
    for column, pred in zip(categorical_columns, predictions.values()):
        predicted_class = label_encoders[column].inverse_transform([np.argmax(pred[0])])[0]
        results[column] = predicted_class

    return results

def predict_and_display_random_images(metadata, model, num_images=5):
    random_images = metadata.sample(n=num_images)

    plt.figure(figsize=(20, 6*num_images))

    for i, (_, row) in enumerate(random_images.iterrows()):
        img = tf.keras.preprocessing.image.load_img(row['image_path'], target_size=img_size)
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0) / 255.0

        predictions = model.predict(img_array)

        results = {}
        for column, pred in zip(categorical_columns, predictions.values()):
            predicted_class = label_encoders[column].inverse_transform([np.argmax(pred[0])])[0]
            results[column] = predicted_class

        plt.subplot(num_images, 2, 2*i+1)
        plt.imshow(img)
        plt.axis('off')
        plt.title("Original Image")

        plt.subplot(num_images, 2, 2*i+2)
        plt.axis('off')
        plt.text(0.1, 0.9, "Predictions:", fontsize=12, fontweight='bold')
        for j, (key, value) in enumerate(results.items()):
            plt.text(0.1, 0.8 - j*0.1, f"{key}: {value}", fontsize=10)

        plt.text(0.6, 0.9, "Actual Values:", fontsize=12, fontweight='bold')
        for j, column in enumerate(categorical_columns):
            plt.text(0.6, 0.8 - j*0.1, f"{column}: {row[column]}", fontsize=10)

    plt.tight_layout()
    plt.show()

predict_and_display_random_images(val_data, model)

